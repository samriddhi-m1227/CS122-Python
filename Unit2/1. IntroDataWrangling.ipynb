{"cells":[{"metadata":{"id":"7639770fd077cea7"},"cell_type":"markdown","source":["# Intro to Data Wrangling\n","* Data wrangling (also known as data munging) refers to the process of cleaning, transforming, and preparing raw data for analysis or machine learning tasks.\n","* It involves tasks such as handling missing values, correcting errors in the data, converting data formats, aggregating data, and ensuring the data is in a usable structure.\n","\n","__NOTE:__\n","- __This is an introductory session. We will deep dive into data analysis with real data post midterm exam 1.__\n","- __After midterm 1 the course shifts to applications with real world data analysis, with databases and web development (the topics maybe intertwined).__\n","- __These concepts will not be part of midterm exam 1__\n"],"id":"7639770fd077cea7"},{"metadata":{"id":"4559271a3b293806"},"cell_type":"markdown","source":["# Overview of Data Wrangling\n","* Data wrangling is a crucial step in any data analysis process. Raw data often comes from various sources such as CSV files, databases, APIs, and web scraping.\n","* These datasets often contain missing or erroneous data, inconsistencies, and unstructured formats.\n","* The goal of data wrangling is to convert this raw data into a clean, structured format that can be used effectively for analysis or machine learning.\n","\n","It includes tasks like:\n","- Cleaning: Removing errors or inconsistencies.\n","- Transforming: Changing data types, values, or structures.\n","- Consolidating: Merging different data sources.\n","- Filtering: Selecting relevant data points.\n","- Feature Engineering: Creating new features from existing data.\n","\n","# Use cases\n","Why is it Important?\n","- Data collected from various sources such as web scraping, APIs, and databases often come in raw forms with inconsistencies.\n","- Cleaning and transforming this data is necessary for obtaining actionable insights.\n","- You cannot perform meaningful analysis, dervie conclusions, or build machine learning models without this step.\n"],"id":"4559271a3b293806"},{"metadata":{"id":"2341f774dde7e311"},"cell_type":"markdown","source":["# Python libraries for Data Wrangling\n","\n","There are many python libraries that can be used for this purpose. We will look at some of the popular ones and also some niche libraries that might be useful for specific types of data.\n"],"id":"2341f774dde7e311"},{"metadata":{"id":"9b5e17283875d56e"},"cell_type":"markdown","source":["\n","### Pandas: The Core Library\n","Pandas provides two main data structures:\n","- DataFrame: A two-dimensional table with labeled axes (rows and columns).\n","- Series: A one-dimensional array with labeled indices.\n","Pandas simplifies data manipulation and preparation through a rich set of functionalities.\n","Basic Operations:\n","* pd.read_csv() to read data from CSV files.\n","* DataFrame.dropna() to remove missing data.\n","* DataFrame.fillna() to replace missing values.\n","* DataFrame.groupby() for aggregation.\n","\n","\n","### NumPy: Handling Numerical Data\n","NumPy is used for numerical computing, and it is especially useful for working with arrays. It supports operations like mathematical calculations, broadcasting, and reshaping data.\n","Key Functions:\n","* np.array() to create NumPy arrays.\n","* np.mean(), np.median() for basic statistics. (many more like this)\n","\n","### Matplotlib & Seaborn: Data Visualization\n","Data wrangling is often followed by visualizing the results to ensure data correctness.\n","* Matplotlib: Provides low-level plotting functionalities.\n","* Seaborn: Built on top of Matplotlib and offers advanced statistical visualizations.\n","\n","### Regex (re module, already covered)\n","* For string manipulation, regular expressions (Regex) allow you to match and extract patterns from text data. For example, removing extra spaces, validating email addresses, or extracting dates.\n","\n","\n"],"id":"9b5e17283875d56e"},{"metadata":{"id":"8faa91580d01f4cd"},"cell_type":"markdown","source":["# Simple Example Intro to pandas usage for data wrangling tasks\n","\n","We will use messy data csv files as example. CSV stands for Comma Separated Values, each row resperents a datapoint, data sample, or entry. Each column represents an attribute or feature.\n","\n","The first row has the name of the columns (optional, but is almost always the case). Pandas can the first row as labels for column.\n","\n","Lets walkthrough some basic data wrangling tasks.\n","\n","### Handling Missing Data\n","\n","There are three main strategies for dealing with missing data:\n","\n","#### Identifying Missing Data:"],"id":"8faa91580d01f4cd"},{"metadata":{"ExecuteTime":{"end_time":"2025-03-12T21:33:52.490111Z","start_time":"2025-03-12T21:33:52.483292Z"},"id":"53d30ab066b9d428","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1742364485072,"user_tz":420,"elapsed":35,"user":{"displayName":"Samriddhi Matharu","userId":"15444417249591811102"}},"outputId":"d36bcc0d-1477-4155-e657-dd9a103ae402"},"cell_type":"code","source":["import pandas\n","import pandas as pd\n","\n","data = pd.read_csv('messy_employee_data.csv')\n","#DATA HAS 12 COLUMNS 10 ROWS\n","#can also use data.info()\n","\n","print(data.shape)\n","print(\"_________________\")\n","print(data)\n","print(\"_________________\")\n","print(data.isnull().sum())  # Shows the count of missing values per column\n","\n"],"id":"53d30ab066b9d428","outputs":[{"output_type":"stream","name":"stdout","text":["(10, 12)\n","_________________\n","   Employee_ID First_Name Last_Name  Gender   Age Department  \\\n","0          101       John       Doe    Male  35.0         HR   \n","1          102       Jane     SMITH  female  28.0         IT   \n","2          103        Sam     Brown    Male  45.0    Finance   \n","3          104      Emily     Davis  Female  30.0         IT   \n","4          105    Michael   Johnson    Male   NaN         HR   \n","5          106      Laura    Wilson  Female  40.0  Marketing   \n","6          107     Daniel     Moore    male  33.0  Marketing   \n","7          108        NaN     Black    male  27.0         HR   \n","8          109   Patricia     Green  Female  55.0         HR   \n","9          101       John       Doe    Male  35.0         HR   \n","\n","            Job_Title   Salary Date_Joined    Bonus Phone_Number  \\\n","0          HR Manager  65000.0  2018-03-01   5000.0     555-1234   \n","1   Software Engineer  85000.0  2020-07-15   7000.0     555-5678   \n","2          Accountant  90000.0  2015-06-23   5500.0     555-2345   \n","3      Data Scientist  95000.0  2019-11-12   8000.0     555-6789   \n","4       HR Specialist  70000.0         NaN      NaN     555-3456   \n","5   Marketing Manager      NaN  2017-04-30   6200.0          NaN   \n","6  Content Strategist  70000.0  2021-01-22   4000.0     555-7890   \n","7        HR Assistant  48000.0  2022-03-15   3000.0     555-4321   \n","8          HR Manager  80000.0  2016-08-19  10000.0     555-1234   \n","9          HR Manager  65000.0  2018-03-01   5000.0     555-1234   \n","\n","                     Email  \n","0       john.doe@gmail.com  \n","1   jane.smith@example.com  \n","2    sam.brown@company.com  \n","3      emily.davis@company  \n","4  michael.johnson@web.com  \n","5      laura@marketing.com  \n","6     daniel.moore@web.net  \n","7    naomi.black@gmail.com  \n","8   patricia.green@com.com  \n","9       john.doe@gmail.com  \n","_________________\n","Employee_ID     0\n","First_Name      1\n","Last_Name       0\n","Gender          0\n","Age             1\n","Department      0\n","Job_Title       0\n","Salary          1\n","Date_Joined     1\n","Bonus           1\n","Phone_Number    1\n","Email           0\n","dtype: int64\n"]}],"execution_count":null},{"metadata":{"id":"5e3d7d4475922efa"},"cell_type":"markdown","source":["#### Removing Missing Data:\n","Multiple ways to handle this. Very rarely used."],"id":"5e3d7d4475922efa"},{"metadata":{"ExecuteTime":{"end_time":"2025-03-11T18:40:56.198164Z","start_time":"2025-03-11T18:40:56.187461Z"},"id":"8b3bf06fe9b2eb9b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741888202951,"user_tz":420,"elapsed":56,"user":{"displayName":"Samriddhi Matharu","userId":"15444417249591811102"}},"outputId":"870cff68-9b5b-4e1b-b8a9-03aa87eff291"},"cell_type":"code","source":["#Remove rows with missing data:\n","data_cleaned1 = data.dropna()\n","#Drop columns with missing data:\n","data_cleaned2 = data.dropna(axis=1) #axis 0 is rows (default), axis 1 is columns\n","print(\"data_cleaned1\")\n","print(data_cleaned1)\n","print(\"____________\")\n","print(\"data_cleaned2\")\n","print(data_cleaned2)\n","\n","# The dropna method in pandas DataFrames includes a thresh parameter that specifies the minimum number of non-missing values a row or column must have to be kept. Rows or columns with fewer non-missing values than the threshold are removed.\n","\n","print(\"____________\")\n","df_thresh_10_row = data.dropna(thresh=10)\n","print(\"\\nDataFrame after dropping rows with less than 10 non-NaN values:\")\n","print(\"data_thresh_10\")\n","print(df_thresh_10_row)\n","\n","#If a row has at least 10 filled (non-NaN) values, it will be kept.\n","#If a row has less than 10 filled values, it will be dropped.\n","\n","\n","print(\"____________\")\n","df_thresh_10_col = data.dropna(thresh=10, axis=1)\n","print(\"data_thresh_10 axis 1\")\n","print(\"\\nDataFrame after dropping columns with less than 10 non-NaN values:\")\n","print(df_thresh_10_col)\n","\n","\n"],"id":"8b3bf06fe9b2eb9b","outputs":[{"output_type":"stream","name":"stdout","text":["data_cleaned1\n","   Employee_ID First_Name Last_Name  Gender   Age Department  \\\n","0          101       John       Doe    Male  35.0         HR   \n","1          102       Jane     SMITH  female  28.0         IT   \n","2          103        Sam     Brown    Male  45.0    Finance   \n","3          104      Emily     Davis  Female  30.0         IT   \n","6          107     Daniel     Moore    male  33.0  Marketing   \n","8          109   Patricia     Green  Female  55.0         HR   \n","9          101       John       Doe    Male  35.0         HR   \n","\n","            Job_Title   Salary Date_Joined    Bonus Phone_Number  \\\n","0          HR Manager  65000.0  2018-03-01   5000.0     555-1234   \n","1   Software Engineer  85000.0  2020-07-15   7000.0     555-5678   \n","2          Accountant  90000.0  2015-06-23   5500.0     555-2345   \n","3      Data Scientist  95000.0  2019-11-12   8000.0     555-6789   \n","6  Content Strategist  70000.0  2021-01-22   4000.0     555-7890   \n","8          HR Manager  80000.0  2016-08-19  10000.0     555-1234   \n","9          HR Manager  65000.0  2018-03-01   5000.0     555-1234   \n","\n","                    Email  \n","0      john.doe@gmail.com  \n","1  jane.smith@example.com  \n","2   sam.brown@company.com  \n","3     emily.davis@company  \n","6    daniel.moore@web.net  \n","8  patricia.green@com.com  \n","9      john.doe@gmail.com  \n","____________\n","data_cleaned2\n","   Employee_ID Last_Name  Gender Department           Job_Title  \\\n","0          101       Doe    Male         HR          HR Manager   \n","1          102     SMITH  female         IT   Software Engineer   \n","2          103     Brown    Male    Finance          Accountant   \n","3          104     Davis  Female         IT      Data Scientist   \n","4          105   Johnson    Male         HR       HR Specialist   \n","5          106    Wilson  Female  Marketing   Marketing Manager   \n","6          107     Moore    male  Marketing  Content Strategist   \n","7          108     Black    male         HR        HR Assistant   \n","8          109     Green  Female         HR          HR Manager   \n","9          101       Doe    Male         HR          HR Manager   \n","\n","                     Email  \n","0       john.doe@gmail.com  \n","1   jane.smith@example.com  \n","2    sam.brown@company.com  \n","3      emily.davis@company  \n","4  michael.johnson@web.com  \n","5      laura@marketing.com  \n","6     daniel.moore@web.net  \n","7    naomi.black@gmail.com  \n","8   patricia.green@com.com  \n","9       john.doe@gmail.com  \n","____________\n","\n","DataFrame after dropping rows with less than 10 non-NaN values:\n","data_thresh_10\n","   Employee_ID First_Name Last_Name  Gender   Age Department  \\\n","0          101       John       Doe    Male  35.0         HR   \n","1          102       Jane     SMITH  female  28.0         IT   \n","2          103        Sam     Brown    Male  45.0    Finance   \n","3          104      Emily     Davis  Female  30.0         IT   \n","5          106      Laura    Wilson  Female  40.0  Marketing   \n","6          107     Daniel     Moore    male  33.0  Marketing   \n","7          108        NaN     Black    male  27.0         HR   \n","8          109   Patricia     Green  Female  55.0         HR   \n","9          101       John       Doe    Male  35.0         HR   \n","\n","            Job_Title   Salary Date_Joined    Bonus Phone_Number  \\\n","0          HR Manager  65000.0  2018-03-01   5000.0     555-1234   \n","1   Software Engineer  85000.0  2020-07-15   7000.0     555-5678   \n","2          Accountant  90000.0  2015-06-23   5500.0     555-2345   \n","3      Data Scientist  95000.0  2019-11-12   8000.0     555-6789   \n","5   Marketing Manager      NaN  2017-04-30   6200.0          NaN   \n","6  Content Strategist  70000.0  2021-01-22   4000.0     555-7890   \n","7        HR Assistant  48000.0  2022-03-15   3000.0     555-4321   \n","8          HR Manager  80000.0  2016-08-19  10000.0     555-1234   \n","9          HR Manager  65000.0  2018-03-01   5000.0     555-1234   \n","\n","                    Email  \n","0      john.doe@gmail.com  \n","1  jane.smith@example.com  \n","2   sam.brown@company.com  \n","3     emily.davis@company  \n","5     laura@marketing.com  \n","6    daniel.moore@web.net  \n","7   naomi.black@gmail.com  \n","8  patricia.green@com.com  \n","9      john.doe@gmail.com  \n","____________\n","data_thresh_10 axis 1\n","\n","DataFrame after dropping columns with less than 10 non-NaN values:\n","   Employee_ID Last_Name  Gender Department           Job_Title  \\\n","0          101       Doe    Male         HR          HR Manager   \n","1          102     SMITH  female         IT   Software Engineer   \n","2          103     Brown    Male    Finance          Accountant   \n","3          104     Davis  Female         IT      Data Scientist   \n","4          105   Johnson    Male         HR       HR Specialist   \n","5          106    Wilson  Female  Marketing   Marketing Manager   \n","6          107     Moore    male  Marketing  Content Strategist   \n","7          108     Black    male         HR        HR Assistant   \n","8          109     Green  Female         HR          HR Manager   \n","9          101       Doe    Male         HR          HR Manager   \n","\n","                     Email  \n","0       john.doe@gmail.com  \n","1   jane.smith@example.com  \n","2    sam.brown@company.com  \n","3      emily.davis@company  \n","4  michael.johnson@web.com  \n","5      laura@marketing.com  \n","6     daniel.moore@web.net  \n","7    naomi.black@gmail.com  \n","8   patricia.green@com.com  \n","9       john.doe@gmail.com  \n"]}],"execution_count":null},{"metadata":{"id":"277333fb3551b9a1"},"cell_type":"markdown","source":["#### Imputing Missing Data:\n","\n","Multiple ways to handle this. Mostly used / goto approach\n"],"id":"277333fb3551b9a1"},{"metadata":{"id":"442ed8b3f683e912","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741889424183,"user_tz":420,"elapsed":8,"user":{"displayName":"Samriddhi Matharu","userId":"15444417249591811102"}},"outputId":"8b8a9a3d-7b63-49ff-f8a9-2dad85dc43d9"},"cell_type":"code","source":["\n","#NOTE if we set \"inplace=TRUE\" for any of the following methods, it will update the original dataframe.\n","#Fill missing values with a default value or the mean/median:\n","#data_filled_def=data[['Salary', 'Bonus', 'Age']].fillna(0) #filling all numeric with specific\n","#data_filled_def = data.fillna(0) #filling default value\n","#print(data_filled_def)\n","\n","#Generally applied first for string columns.\n","#print(data.dtypes) # prints the data types for each column. We will look into setting and changing data types of columns later.\n","data_filled_def = data.fillna({'First_Name': 'Unknown','Date_Joined': 'Unknown','Phone_Number': 'Unknown'}) # filling specific columns with default values\n","#print(data_filled_def)\n","\n","#one trick to get all columnnames that are numeric. (non object).\n","# numeric_cols = data_filled_def.select_dtypes(exclude='object').columns\n","# #if it is a completly numeric dataframe, we can just use data.mean().\n","# #filling with mean values, only works with numerical columns.\n","# data_filled_mean = data_filled_def.fillna(data_filled_def[numeric_cols].mean())\n","# #print(\"_______________\")\n","# print(data_filled_mean)\n","\n","#Forward or Backward Filling:\n","#data_ffill = data.ffill() #fill forward (takes the PRECEDING value) (goes from top bottom)\n","#print(\"_______________\")\n","#print(data_ffill)\n","#\n","data_bfill = data.bfill() #fill backward (takes the SUCCEEDING value ) (from bottom top)\n","print(\"_______________\")\n","print(data_bfill)\n"],"id":"442ed8b3f683e912","outputs":[{"output_type":"stream","name":"stdout","text":["_______________\n","   Employee_ID First_Name Last_Name  Gender   Age Department  \\\n","0          101       John       Doe    Male  35.0         HR   \n","1          102       Jane     SMITH  female  28.0         IT   \n","2          103        Sam     Brown    Male  45.0    Finance   \n","3          104      Emily     Davis  Female  30.0         IT   \n","4          105    Michael   Johnson    Male  40.0         HR   \n","5          106      Laura    Wilson  Female  40.0  Marketing   \n","6          107     Daniel     Moore    male  33.0  Marketing   \n","7          108   Patricia     Black    male  27.0         HR   \n","8          109   Patricia     Green  Female  55.0         HR   \n","9          101       John       Doe    Male  35.0         HR   \n","\n","            Job_Title   Salary Date_Joined    Bonus Phone_Number  \\\n","0          HR Manager  65000.0  2018-03-01   5000.0     555-1234   \n","1   Software Engineer  85000.0  2020-07-15   7000.0     555-5678   \n","2          Accountant  90000.0  2015-06-23   5500.0     555-2345   \n","3      Data Scientist  95000.0  2019-11-12   8000.0     555-6789   \n","4       HR Specialist  70000.0  2017-04-30   6200.0     555-3456   \n","5   Marketing Manager  70000.0  2017-04-30   6200.0     555-7890   \n","6  Content Strategist  70000.0  2021-01-22   4000.0     555-7890   \n","7        HR Assistant  48000.0  2022-03-15   3000.0     555-4321   \n","8          HR Manager  80000.0  2016-08-19  10000.0     555-1234   \n","9          HR Manager  65000.0  2018-03-01   5000.0     555-1234   \n","\n","                     Email  \n","0       john.doe@gmail.com  \n","1   jane.smith@example.com  \n","2    sam.brown@company.com  \n","3      emily.davis@company  \n","4  michael.johnson@web.com  \n","5      laura@marketing.com  \n","6     daniel.moore@web.net  \n","7    naomi.black@gmail.com  \n","8   patricia.green@com.com  \n","9       john.doe@gmail.com  \n"]}],"execution_count":null},{"metadata":{"id":"2cf511094d3d3b19"},"cell_type":"markdown","source":["### Removing Duplicates\n","\n","Duplicate data often distorts the results, especially in large datasets.\n","\n","#### Identifying Duplicates:\n","\n"],"id":"2cf511094d3d3b19"},{"metadata":{"id":"e7e2e20a018f280d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741889477802,"user_tz":420,"elapsed":125,"user":{"displayName":"Samriddhi Matharu","userId":"15444417249591811102"}},"outputId":"ea27e94a-722d-44cd-dc8e-588eb05110ef"},"cell_type":"code","source":["print(data.duplicated())  # Returns True for duplicate rows (in this case the 9th row was a duplicate of the first )"],"id":"e7e2e20a018f280d","outputs":[{"output_type":"stream","name":"stdout","text":["0    False\n","1    False\n","2    False\n","3    False\n","4    False\n","5    False\n","6    False\n","7    False\n","8    False\n","9     True\n","dtype: bool\n"]}],"execution_count":null},{"metadata":{"id":"24c0e93cc87fcf2e"},"cell_type":"markdown","source":["#### Removing Duplicates:"],"id":"24c0e93cc87fcf2e"},{"metadata":{"id":"2d33ad597f9f9688"},"cell_type":"code","source":["print(data)\n","#Remove exact duplicate rows:\n","# data_cleaned1 = data.drop_duplicates()\n","# print(data_cleaned1)\n","#Remove duplicates based on specific columns:\n","# data_cleaned2 = data.drop_duplicates(subset=['Salary']) #even if other columns are diff is salary matches it will drop the second one and onwards\n","# print(data_cleaned2)\n"],"id":"2d33ad597f9f9688","outputs":[],"execution_count":null},{"metadata":{"id":"887ae579f3b47d73"},"cell_type":"code","source":[],"id":"887ae579f3b47d73","outputs":[],"execution_count":null},{"metadata":{"id":"f8ec2c005fe2f961"},"cell_type":"markdown","source":["Before we move on...\n","* read_csv can also be used to read other types of files, you can specify your own separator. basic syntax:  pd.read_csv(\"\\<finename.extension\\>\", sep=\"\\<separator\\>\")\n","* You can also specify data types (dtype) of the column, and specify NaN values (na_values)  during the read call.\n","* Refer Biological data exploration with Python, pandas and seaborn - pages 14 onwards.\n","\n","\n","* Test these out:\n","dataframe.info() can give you:\n","    - what class the object is (a DataFrame )\n","    - what the index looks like (a range )\n","    - how many data columns we have\n","    - for each column, how many values and their dtype\n","    - a summary of how many columns have each dtype\n","\n","and dataframe.describe() can give you some basic statistics of each column.\n"],"id":"f8ec2c005fe2f961"},{"metadata":{"id":"70141eadfcc34443"},"cell_type":"markdown","source":["* You can also specify your own column names and add it either while reading file or after that."],"id":"70141eadfcc34443"},{"metadata":{"id":"12cb12492a4e81ec","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741890073941,"user_tz":420,"elapsed":49,"user":{"displayName":"Samriddhi Matharu","userId":"15444417249591811102"}},"outputId":"27a67581-156c-434b-87d9-8c708de4f1f8"},"cell_type":"code","outputs":[{"output_type":"stream","name":"stdout","text":["          col1        col2       col3    col4  col5        col6  \\\n","0  Employee_ID  First_Name  Last_Name  Gender   Age  Department   \n","1          101        John        Doe    Male  35.0          HR   \n","2          102        Jane      SMITH  female  28.0          IT   \n","3          103         Sam      Brown    Male  45.0     Finance   \n","4          104       Emily      Davis  Female  30.0          IT   \n","\n","                col7     col8         col9   col10         col11  \\\n","0          Job_Title   Salary  Date_Joined   Bonus  Phone_Number   \n","1         HR Manager  65000.0   2018-03-01  5000.0      555-1234   \n","2  Software Engineer  85000.0   2020-07-15  7000.0      555-5678   \n","3         Accountant  90000.0   2015-06-23  5500.0      555-2345   \n","4     Data Scientist  95000.0   2019-11-12  8000.0      555-6789   \n","\n","                    col12  \n","0                   Email  \n","1      john.doe@gmail.com  \n","2  jane.smith@example.com  \n","3   sam.brown@company.com  \n","4     emily.davis@company  \n","   col1     col2      col3    col4  col5     col6               col7     col8  \\\n","0   101     John       Doe    Male  35.0       HR         HR Manager  65000.0   \n","1   102     Jane     SMITH  female  28.0       IT  Software Engineer  85000.0   \n","2   103      Sam     Brown    Male  45.0  Finance         Accountant  90000.0   \n","3   104    Emily     Davis  Female  30.0       IT     Data Scientist  95000.0   \n","4   105  Michael   Johnson    Male   NaN       HR      HR Specialist  70000.0   \n","\n","         col9   col10     col11                    col12  \n","0  2018-03-01  5000.0  555-1234       john.doe@gmail.com  \n","1  2020-07-15  7000.0  555-5678   jane.smith@example.com  \n","2  2015-06-23  5500.0  555-2345    sam.brown@company.com  \n","3  2019-11-12  8000.0  555-6789      emily.davis@company  \n","4         NaN     NaN  555-3456  michael.johnson@web.com  \n"]}],"execution_count":null,"source":["# example for using own column names\n","\n","my_columns=[\"col1\", \"col2\", \"col3\", \"col4\", \"col5\", \"col6\", \"col7\", \"col8\", \"col9\", \"col10\",\"col11\",\"col12\"]\n","#note it considers first line as data in this method.\n","example1=pd.read_csv('messy_employee_data.csv',names=my_columns, na_values='?')#does not fully replace names\n","print(example1.head())\n","\n","#note this replaces the column names , this method.\n","example2=pd.read_csv('messy_employee_data.csv')\n","example2.columns = my_columns\n","print(example2.head())"],"id":"12cb12492a4e81ec"},{"metadata":{"id":"2c9bea82ab3dbede"},"cell_type":"markdown","source":["\n","# Series\n","\n","* You can build a dataframe with Series objects\n","* Pandas provides a rich set of functionalities with Series objects are one-dimensional arrays.\n","* Boardcasting operations is a very useful tool.\n","* Each column in a dataframe is considered a series.\n"],"id":"2c9bea82ab3dbede"},{"metadata":{"ExecuteTime":{"end_time":"2025-03-12T23:46:41.144464Z","start_time":"2025-03-12T23:46:41.138692Z"},"id":"767ea97416b939af","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1742454890105,"user_tz":420,"elapsed":81,"user":{"displayName":"Samriddhi Matharu","userId":"15444417249591811102"}},"outputId":"7b6839a4-cbf8-40f8-824d-cb76890853e1"},"cell_type":"code","source":["import pandas as pd\n","#these are all individual Series you can call them alone (the columns) but u can also make two columns or more a DF\n","\n","# building dataframe with Series objects\n","print(\"_______________\")\n","a = pd.Series([1,2,3,4,5,6,7,8,9])\n","b=pd.Series([\"One\",\"Two\",\"Three\",\"Four\",\"Five\",\"Six\",\"Seven\"])\n","c=pd.Series([0,1,0,1,0,1,0,1,0,1])\n","newdata=pd.DataFrame({\"column1\":a,\"column2\":b})\n","\n","print(newdata)\n","print(\"_______________\")\n","\n","#you can additionaly specify datatype with dtype attribute for Series\n","\n","#broadcasting\n","print(a * 2)\n","print(\"_______________\")\n","newdata['c']=newdata['column1'] * c\n","print(newdata)\n","print(type(newdata['column1']))\n","\n","print(\"_______________\")\n","print(a**2)"],"id":"767ea97416b939af","outputs":[{"output_type":"stream","name":"stdout","text":["_______________\n","   column1 column2\n","0        1     One\n","1        2     Two\n","2        3   Three\n","3        4    Four\n","4        5    Five\n","5        6     Six\n","6        7   Seven\n","7        8     NaN\n","8        9     NaN\n","_______________\n","0     2\n","1     4\n","2     6\n","3     8\n","4    10\n","5    12\n","6    14\n","7    16\n","8    18\n","dtype: int64\n","_______________\n","   column1 column2    c\n","0        1     One  0.0\n","1        2     Two  2.0\n","2        3   Three  0.0\n","3        4    Four  4.0\n","4        5    Five  0.0\n","5        6     Six  6.0\n","6        7   Seven  0.0\n","7        8     NaN  8.0\n","8        9     NaN  0.0\n","<class 'pandas.core.series.Series'>\n","_______________\n","0     1\n","1     4\n","2     9\n","3    16\n","4    25\n","5    36\n","6    49\n","7    64\n","8    81\n","dtype: int64\n"]}],"execution_count":null},{"metadata":{"id":"31d7afa74502fb9f"},"cell_type":"markdown","source":["### Changing Data Types\n","Changing data types is crucial for analysis. For example, dates are better represented as datetime objects than as strings.\n","\n","\n","#### Convert Columns to Correct Data Types:\n","An example with date type\n"],"id":"31d7afa74502fb9f"},{"metadata":{"id":"78b181acebab963d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741890965112,"user_tz":420,"elapsed":46,"user":{"displayName":"Samriddhi Matharu","userId":"15444417249591811102"}},"outputId":"ecd90076-c020-467d-f473-744f4a7023c4"},"cell_type":"code","source":["# Convert a column to datetime\n","data_1 = data.drop_duplicates() #dropping duplicates\n","data_1['Date_Joined'] = pd.to_datetime(data_1['Date_Joined'])\n","# date time objects allow you to call specific functions on them. Like getting the delta and so on.\n","# Convert numerical column to integer\n","data_1 = data_1.fillna({'Salary': 0})\n","data_1['Salary'] = data_1['Salary'].astype('int')\n","\n","#Check Data Types:\n","print(data_1.dtypes)\n"],"id":"78b181acebab963d","outputs":[{"output_type":"stream","name":"stdout","text":["Employee_ID              int64\n","First_Name              object\n","Last_Name               object\n","Gender                  object\n","Age                    float64\n","Department              object\n","Job_Title               object\n","Salary                   int64\n","Date_Joined     datetime64[ns]\n","Bonus                  float64\n","Phone_Number            object\n","Email                   object\n","dtype: object\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-20-7ff46274eb94>:3: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data_1['Date_Joined'] = pd.to_datetime(data_1['Date_Joined'])\n"]}],"execution_count":null},{"metadata":{"id":"f48db4c88e6de947"},"cell_type":"markdown","source":["### String Manipulation\n","Strings need to be cleaned or transformed for consistency.\n"],"id":"f48db4c88e6de947"},{"metadata":{"id":"139d7acb2d2585e1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741891261374,"user_tz":420,"elapsed":28,"user":{"displayName":"Samriddhi Matharu","userId":"15444417249591811102"}},"outputId":"fc449b74-71a3-41dd-81d8-58273c67bdb8"},"cell_type":"code","source":["#Example 1: Stripping Whitespace\n","data_1['First_Name'] = data_1['First_Name'].str.strip()  # Remove leading/trailing whitespaces(does on entire column)\n","print(data_1.dtypes)\n","#Example 2: Extracting Patterns with Regex\n","#creating a new column\n","import re\n","data_1['year'] = data_1['Date_Joined'].astype(str).str.extract(r'(\\d{4})')  # Extract year from a date string, there are other ways to do this as it was already a datatime object\n","#Example 3: Replacing Values\n","#data_1['Gender'] = data_1['Gender'].replace({'male': 'M','Male': 'M', 'female': 'F','Female': 'F'})\n","data_1['Gender'] = data_1['Gender'].replace({re.compile('[mM]ale'): 'M',re.compile('[fF]emale'): 'F'})\n","print(data_1)\n","\n","\n"],"id":"139d7acb2d2585e1","outputs":[{"output_type":"stream","name":"stdout","text":["Employee_ID              int64\n","First_Name              object\n","Last_Name               object\n","Gender                  object\n","Age                    float64\n","Department              object\n","Job_Title               object\n","Salary                   int64\n","Date_Joined     datetime64[ns]\n","Bonus                  float64\n","Phone_Number            object\n","Email                   object\n","dtype: object\n","   Employee_ID First_Name Last_Name  Gender   Age Department  \\\n","0          101       John       Doe    Male  35.0         HR   \n","1          102       Jane     SMITH  female  28.0         IT   \n","2          103        Sam     Brown    Male  45.0    Finance   \n","3          104      Emily     Davis  Female  30.0         IT   \n","4          105    Michael   Johnson    Male   NaN         HR   \n","5          106      Laura    Wilson  Female  40.0  Marketing   \n","6          107     Daniel     Moore    male  33.0  Marketing   \n","7          108        NaN     Black    male  27.0         HR   \n","8          109   Patricia     Green  Female  55.0         HR   \n","\n","            Job_Title  Salary Date_Joined    Bonus Phone_Number  \\\n","0          HR Manager   65000  2018-03-01   5000.0     555-1234   \n","1   Software Engineer   85000  2020-07-15   7000.0     555-5678   \n","2          Accountant   90000  2015-06-23   5500.0     555-2345   \n","3      Data Scientist   95000  2019-11-12   8000.0     555-6789   \n","4       HR Specialist   70000         NaT      NaN     555-3456   \n","5   Marketing Manager       0  2017-04-30   6200.0          NaN   \n","6  Content Strategist   70000  2021-01-22   4000.0     555-7890   \n","7        HR Assistant   48000  2022-03-15   3000.0     555-4321   \n","8          HR Manager   80000  2016-08-19  10000.0     555-1234   \n","\n","                     Email  year  \n","0       john.doe@gmail.com  2018  \n","1   jane.smith@example.com  2020  \n","2    sam.brown@company.com  2015  \n","3      emily.davis@company  2019  \n","4  michael.johnson@web.com   NaN  \n","5      laura@marketing.com  2017  \n","6     daniel.moore@web.net  2021  \n","7    naomi.black@gmail.com  2022  \n","8   patricia.green@com.com  2016  \n"]}],"execution_count":null},{"metadata":{"id":"7c5bc8b6ecebc878"},"cell_type":"code","source":["#can tackle part a and b in hw"],"id":"7c5bc8b6ecebc878","outputs":[],"execution_count":null},{"metadata":{"id":"d5ff81b9b8908356"},"cell_type":"markdown","source":["\n","## Merging DAtasets:\n","Merging datasets is useful when combining data from different sources or tables."],"id":"d5ff81b9b8908356"},{"metadata":{"id":"4545481efbbf4a1a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1742365049187,"user_tz":420,"elapsed":45,"user":{"displayName":"Samriddhi Matharu","userId":"15444417249591811102"}},"outputId":"3a0c56bc-396b-4994-a6b5-667296ad4288"},"cell_type":"code","source":["print(data)\n","\n","newdata=pd.read_csv(\"messy_employee_data2.csv\")\n","print('-----------------------------------------------------------------------------')\n","\n","print(newdata)\n","\n","#merged_data = pd.merge(data, newdata, how='outer')\n","\n","#you can use \"on\" attribute if useing only few common columns\n","merged_data = pd.merge(data, newdata,on=\"Employee_ID\", how='outer') #'outer' acts as an 'OR' so it includes all rows. 'inner' acts as the AND (only matches from the 'on')\n","print(merged_data)\n","#merged_data=merged_data.drop_duplicates()\n","#merged_data['Gender'] = merged_data['Gender'].replace({'male': 'M','Male': 'M', 'female': 'F','Female': 'F'})"],"id":"4545481efbbf4a1a","outputs":[{"output_type":"stream","name":"stdout","text":["   Employee_ID First_Name Last_Name  Gender   Age Department  \\\n","0          101       John       Doe    Male  35.0         HR   \n","1          102       Jane     SMITH  female  28.0         IT   \n","2          103        Sam     Brown    Male  45.0    Finance   \n","3          104      Emily     Davis  Female  30.0         IT   \n","4          105    Michael   Johnson    Male   NaN         HR   \n","5          106      Laura    Wilson  Female  40.0  Marketing   \n","6          107     Daniel     Moore    male  33.0  Marketing   \n","7          108        NaN     Black    male  27.0         HR   \n","8          109   Patricia     Green  Female  55.0         HR   \n","9          101       John       Doe    Male  35.0         HR   \n","\n","            Job_Title   Salary Date_Joined    Bonus Phone_Number  \\\n","0          HR Manager  65000.0  2018-03-01   5000.0     555-1234   \n","1   Software Engineer  85000.0  2020-07-15   7000.0     555-5678   \n","2          Accountant  90000.0  2015-06-23   5500.0     555-2345   \n","3      Data Scientist  95000.0  2019-11-12   8000.0     555-6789   \n","4       HR Specialist  70000.0         NaN      NaN     555-3456   \n","5   Marketing Manager      NaN  2017-04-30   6200.0          NaN   \n","6  Content Strategist  70000.0  2021-01-22   4000.0     555-7890   \n","7        HR Assistant  48000.0  2022-03-15   3000.0     555-4321   \n","8          HR Manager  80000.0  2016-08-19  10000.0     555-1234   \n","9          HR Manager  65000.0  2018-03-01   5000.0     555-1234   \n","\n","                     Email  \n","0       john.doe@gmail.com  \n","1   jane.smith@example.com  \n","2    sam.brown@company.com  \n","3      emily.davis@company  \n","4  michael.johnson@web.com  \n","5      laura@marketing.com  \n","6     daniel.moore@web.net  \n","7    naomi.black@gmail.com  \n","8   patricia.green@com.com  \n","9       john.doe@gmail.com  \n","-----------------------------------------------------------------------------\n","   Employee_ID First_Name  Last_Name  Gender   Age Department  \\\n","0          201       Hulk       Iron    Male  35.0         HR   \n","1          202       Bane      SMITH  female  28.0         IT   \n","2          203     Batman     Spider    Male  45.0    Finance   \n","\n","           Job_Title   Salary Date_Joined   Bonus Phone_Number  \\\n","0         HR Manager  65000.0  2024-03-01  5000.0     535-1234   \n","1  Software Engineer  85000.0  2024-07-15  7000.0     551-5678   \n","2         Accountant  90000.0  2024-06-23  5500.0     525-2345   \n","\n","               Email  \n","0    user1@gmail.com  \n","1  user2@example.com  \n","2  user3@company.com  \n","    Employee_ID First_Name_x Last_Name_x Gender_x  Age_x Department_x  \\\n","0           101         John         Doe     Male   35.0           HR   \n","1           101         John         Doe     Male   35.0           HR   \n","2           102         Jane       SMITH   female   28.0           IT   \n","3           103          Sam       Brown     Male   45.0      Finance   \n","4           104        Emily       Davis   Female   30.0           IT   \n","5           105      Michael     Johnson     Male    NaN           HR   \n","6           106        Laura      Wilson   Female   40.0    Marketing   \n","7           107       Daniel       Moore     male   33.0    Marketing   \n","8           108          NaN       Black     male   27.0           HR   \n","9           109     Patricia       Green   Female   55.0           HR   \n","10          201          NaN         NaN      NaN    NaN          NaN   \n","11          202          NaN         NaN      NaN    NaN          NaN   \n","12          203          NaN         NaN      NaN    NaN          NaN   \n","\n","           Job_Title_x  Salary_x Date_Joined_x  Bonus_x  ... Last_Name_y  \\\n","0           HR Manager   65000.0    2018-03-01   5000.0  ...         NaN   \n","1           HR Manager   65000.0    2018-03-01   5000.0  ...         NaN   \n","2    Software Engineer   85000.0    2020-07-15   7000.0  ...         NaN   \n","3           Accountant   90000.0    2015-06-23   5500.0  ...         NaN   \n","4       Data Scientist   95000.0    2019-11-12   8000.0  ...         NaN   \n","5        HR Specialist   70000.0           NaN      NaN  ...         NaN   \n","6    Marketing Manager       NaN    2017-04-30   6200.0  ...         NaN   \n","7   Content Strategist   70000.0    2021-01-22   4000.0  ...         NaN   \n","8         HR Assistant   48000.0    2022-03-15   3000.0  ...         NaN   \n","9           HR Manager   80000.0    2016-08-19  10000.0  ...         NaN   \n","10                 NaN       NaN           NaN      NaN  ...        Iron   \n","11                 NaN       NaN           NaN      NaN  ...       SMITH   \n","12                 NaN       NaN           NaN      NaN  ...      Spider   \n","\n","   Gender_y Age_y Department_y        Job_Title_y  Salary_y Date_Joined_y  \\\n","0       NaN   NaN          NaN                NaN       NaN           NaN   \n","1       NaN   NaN          NaN                NaN       NaN           NaN   \n","2       NaN   NaN          NaN                NaN       NaN           NaN   \n","3       NaN   NaN          NaN                NaN       NaN           NaN   \n","4       NaN   NaN          NaN                NaN       NaN           NaN   \n","5       NaN   NaN          NaN                NaN       NaN           NaN   \n","6       NaN   NaN          NaN                NaN       NaN           NaN   \n","7       NaN   NaN          NaN                NaN       NaN           NaN   \n","8       NaN   NaN          NaN                NaN       NaN           NaN   \n","9       NaN   NaN          NaN                NaN       NaN           NaN   \n","10     Male  35.0           HR         HR Manager   65000.0    2024-03-01   \n","11   female  28.0           IT  Software Engineer   85000.0    2024-07-15   \n","12     Male  45.0      Finance         Accountant   90000.0    2024-06-23   \n","\n","   Bonus_y  Phone_Number_y            Email_y  \n","0      NaN             NaN                NaN  \n","1      NaN             NaN                NaN  \n","2      NaN             NaN                NaN  \n","3      NaN             NaN                NaN  \n","4      NaN             NaN                NaN  \n","5      NaN             NaN                NaN  \n","6      NaN             NaN                NaN  \n","7      NaN             NaN                NaN  \n","8      NaN             NaN                NaN  \n","9      NaN             NaN                NaN  \n","10  5000.0        535-1234    user1@gmail.com  \n","11  7000.0        551-5678  user2@example.com  \n","12  5500.0        525-2345  user3@company.com  \n","\n","[13 rows x 23 columns]\n"]}],"execution_count":null},{"metadata":{"id":"7e2343828d91f1f5"},"cell_type":"markdown","source":["* Inner Merge:\n","Returns only rows where the merge key (column or index) exists in both dataframes. This is the default merge type.\n","* Outer Merge:\n","Returns all rows from both dataframes. If a row exists in one dataframe but not the other, missing values (NaN) are added.\n","* Left Merge:\n","Returns all rows from the \"left\" dataframe and matching rows from the \"right\" dataframe. Non-matching rows from the right dataframe result in NaN values.\n","* Right Merge:\n","Returns all rows from the \"right\" dataframe and matching rows from the \"left\" dataframe. Non-matching rows from the left dataframe result in NaN values.\n","_______________\n","\n","* The on parameter specifies the column(s) to merge on. If column names differ, left_on and right_on can be used. Merging on index is possible using left_index=True or right_index=True.\n","* Without specifying the on argument, the merge() function automatically looks for columns with the same names in both DataFrames. If it finds one or more columns with matching names, it uses those columns as the join keys. This behavior is equivalent to explicitly specifying the on argument with the common column names. If no common columns are found, and neither left_index nor right_index is set to True, the function will raise a MergeError."],"id":"7e2343828d91f1f5"},{"metadata":{"id":"fcc8873c35a78d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1742366061893,"user_tz":420,"elapsed":18,"user":{"displayName":"Samriddhi Matharu","userId":"15444417249591811102"}},"outputId":"e55e95a8-3698-4643-dd91-bde2217da502"},"cell_type":"code","source":["import pandas as pd\n","\n","# Sample DataFrames\n","df1 = pd.DataFrame({'ID': [1, 2, 3], 'Name': ['Amith', 'Kamath', 'Belman']})\n","df2 = pd.DataFrame({'ID': [2, 3, 4], 'Type': [\"First\", \"Last1\", \"Last2\"]})\n","\n","print(df1)\n","print(df2)\n","print('-----------------------------------------------------------------------------------')\n","# Inner Merge (default)\n","inner_merged = pd.merge(df1, df2, on='ID')\n","print(\"inner_merged\")\n","print(inner_merged)\n","print('-----------------------------------------------------------------------------------')\n","# Outer Merge\n","outer_merged = pd.merge(df1, df2, on='ID', how='outer')\n","print(\"outer_merged\")\n","print(outer_merged)\n","print('-----------------------------------------------------------------------------------')\n","# Left Merge\n","left_merged = pd.merge(df1, df2, on='ID', how='left')\n","print(\"left_merged\")\n","print(left_merged)\n","print('-----------------------------------------------------------------------------------')\n","# Right Merge\n","right_merged = pd.merge(df1, df2, on='ID', how='right')\n","print(\"right_merged\")\n","print(right_merged)"],"id":"fcc8873c35a78d","outputs":[{"output_type":"stream","name":"stdout","text":["   ID    Name\n","0   1   Amith\n","1   2  Kamath\n","2   3  Belman\n","   ID   Type\n","0   2  First\n","1   3  Last1\n","2   4  Last2\n","-----------------------------------------------------------------------------------\n","inner_merged\n","   ID    Name   Type\n","0   2  Kamath  First\n","1   3  Belman  Last1\n","-----------------------------------------------------------------------------------\n","outer_merged\n","   ID    Name   Type\n","0   1   Amith    NaN\n","1   2  Kamath  First\n","2   3  Belman  Last1\n","3   4     NaN  Last2\n","-----------------------------------------------------------------------------------\n","left_merged\n","   ID    Name   Type\n","0   1   Amith    NaN\n","1   2  Kamath  First\n","2   3  Belman  Last1\n","-----------------------------------------------------------------------------------\n","right_merged\n","   ID    Name   Type\n","0   2  Kamath  First\n","1   3  Belman  Last1\n","2   4     NaN  Last2\n"]}],"execution_count":null},{"metadata":{"id":"d92b969af50f83f9"},"cell_type":"markdown","source":["\n","### Dataframe Transformations\n","\n","#### pivot and pivot_table\n","\n","* The pivot() function in the Pandas library is used to reshape a DataFrame by converting unique values from one column into new columns. This is useful for transforming data from a \"long\" format to a \"wide\" format.\n","* basic syntax: df.pivot(index, columns, values)\n","\n","* If index contains duplicates, you can use pivot_table\n","* basic syntax: df.pivot_table(index, columns, values, aggfunc optional, fill_value optional)\n","\n","values: The column to aggregate.\n","index: The column to group by on the pivot table index (rows).\n","columns: The column to group by on the pivot table columns.\n","aggfunc: The aggregation function to use (e.g., sum, mean, count). Defaults to mean.\n","fill_value: Value to replace missing values with. default NaN.\n","\n","#### groupby\n","* The groupby() method in pandas is used to group rows in a DataFrame based on the values in one or more columns. This allows you to perform aggregate functions on each group, such as calculating the sum, mean, size, or count and so on.\n","* basic syntax: df.groupby(\\[columns\\])\\[selection column\\].agg(\\[aggregation function\\])\n"],"id":"d92b969af50f83f9"},{"metadata":{"ExecuteTime":{"end_time":"2025-03-12T21:53:27.215567Z","start_time":"2025-03-12T21:53:27.210638Z"},"id":"3b98fe6b5bcf0647","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743891003286,"user_tz":420,"elapsed":1661,"user":{"displayName":"Samriddhi Matharu","userId":"15444417249591811102"}},"outputId":"7f3419bd-7d15-42bb-fd60-07c5a1dfa949"},"cell_type":"code","source":["import pandas as pd\n","\n","df = pd.DataFrame({'A': ['foo', 'foo', 'bar', 'bar',\n","                         'foo', 'foo', 'bar', 'bar'],\n","                    'B': ['one', 'one', 'one', 'two',\n","                         'two', 'two', 'one', 'two'],\n","                    'C': [1, 2, 3, 4, 5, 6, 7, 8],\n","                    'D': [9, 10, 11, 12, 13, 14, 15, 16]})\n","print(\"Original data\")\n","print(df)\n","# assume I want to compute avereage C value  per value of 'A'\n","# we can use groupby\n","print('Groupby example')\n","print(df.groupby(['A'])['C'].agg(['mean']))\n","print(\"__________________\")\n","\n"],"id":"3b98fe6b5bcf0647","outputs":[{"output_type":"stream","name":"stdout","text":["Original data\n","     A    B  C   D\n","0  foo  one  1   9\n","1  foo  one  2  10\n","2  bar  one  3  11\n","3  bar  two  4  12\n","4  foo  two  5  13\n","5  foo  two  6  14\n","6  bar  one  7  15\n","7  bar  two  8  16\n","Groupby example\n","     mean\n","A        \n","bar   5.5\n","foo   3.5\n","__________________\n"]}],"execution_count":2},{"metadata":{"ExecuteTime":{"end_time":"2025-03-12T22:00:26.149930Z","start_time":"2025-03-12T22:00:26.058725Z"},"id":"573b7a83f84f554a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743891005134,"user_tz":420,"elapsed":100,"user":{"displayName":"Samriddhi Matharu","userId":"15444417249591811102"}},"outputId":"1aa4a6cd-8172-484b-a541-2b8148eb3a64"},"cell_type":"code","source":["#what if I want to compute average of C value per value of A per value of B\n","print(\"__________________\")\n","print(\"with groupby\")\n","print(df.groupby(['A','B'])['C'].agg(['mean'])),((['count']))\n","\n","\n","#pivot table is useful when we are using two or more categorical values like above.\n","\n","#what if I want to compute average of C value per value of A per value of B\n","print(\"__________________\")\n","print(\"with pivot_table\")\n","pivoted_df = df.pivot_table(index='A', columns='B', values='C',aggfunc='mean')\n","print(pivoted_df)\n","#you can use aggfunc parameter to set aggregation function to other things, like min, max and so on.\n"],"id":"573b7a83f84f554a","outputs":[{"output_type":"stream","name":"stdout","text":["__________________\n","with groupby\n","         mean\n","A   B        \n","bar one   5.0\n","    two   6.0\n","foo one   1.5\n","    two   5.5\n","__________________\n","with pivot_table\n","B    one  two\n","A            \n","bar  5.0  6.0\n","foo  1.5  5.5\n"]}],"execution_count":3},{"metadata":{"ExecuteTime":{"end_time":"2025-03-12T22:14:33.970507Z","start_time":"2025-03-12T22:14:33.933869Z"},"id":"c3876c84cff94f70","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1742372182610,"user_tz":420,"elapsed":52,"user":{"displayName":"Samriddhi Matharu","userId":"15444417249591811102"}},"outputId":"2f3d6302-959a-4f6f-ca86-b6a8ba85015d"},"cell_type":"code","source":["\n","#hands-on activity\n","\n","import seaborn as sns\n","tipsdata=sns.load_dataset('tips')\n","\n","print(tipsdata.shape)\n","print(tipsdata.columns)\n","print(tipsdata.head())\n","\n","print(\"______________\")\n","# how much did people tip on average per day of week per time  of day?\n","mean_day=print(tipsdata.groupby(['day', 'time'])['tip'].agg(['mean']))\n","\n","\n","print(\"______________\")\n","\n","#what is the average party size at time of day (lunch at dinner), what is the max and min party size.\n","avg_size=print(tipsdata.groupby(['time'])['size'].agg(['mean']))\n","print(\"______________\")\n","avg_size=print(tipsdata.groupby(['time'])['size'].agg(['min']))\n","print(\"______________\")\n","avg_size=print(tipsdata.groupby(['time'])['size'].agg(['max']))\n","print(\"______________\")\n","\n","#how much do people tip (average, max, min) per gender per smoker type per size do this with both groupby and pivot table.\n","\n","print(tipsdata.groupby(['sex','smoker','size'])['tip'].agg(['mean'])),((['max'])),((['min']))\n","print(\"______________\")\n","pivoted_tips=tipsdata.pivot_table(index='smoker',columns=('sex', 'size'), values='tip',aggfunc=('mean', 'max', 'min'))\n","print(pivoted_tips)\n","\n","\"\"\"\n","#pivot table is useful when we are using two or more categorical values like above.\n","\n","#what if I want to compute average of C value per value of A per value of B\n","print(\"__________________\")\n","print(\"with pivot_table\")\n","pivoted_df = df.pivot_table(index='A', columns='B', values='C',aggfunc='mean')\n","print(pivoted_df)\n","#you can use aggfunc parameter to set aggregation function to other things, like min, max and so on.\n","\"\"\"\n","\n","\n"],"id":"c3876c84cff94f70","outputs":[{"output_type":"stream","name":"stdout","text":["(244, 7)\n","Index(['total_bill', 'tip', 'sex', 'smoker', 'day', 'time', 'size'], dtype='object')\n","   total_bill   tip     sex smoker  day    time  size\n","0       16.99  1.01  Female     No  Sun  Dinner     2\n","1       10.34  1.66    Male     No  Sun  Dinner     3\n","2       21.01  3.50    Male     No  Sun  Dinner     3\n","3       23.68  3.31    Male     No  Sun  Dinner     2\n","4       24.59  3.61  Female     No  Sun  Dinner     4\n","______________\n","                 mean\n","day  time            \n","Thur Lunch   2.767705\n","     Dinner  3.000000\n","Fri  Lunch   2.382857\n","     Dinner  2.940000\n","Sat  Lunch        NaN\n","     Dinner  2.993103\n","Sun  Lunch        NaN\n","     Dinner  3.255132\n","______________\n","            mean\n","time            \n","Lunch   2.411765\n","Dinner  2.630682\n","______________\n","        min\n","time       \n","Lunch     1\n","Dinner    1\n","______________\n","        max\n","time       \n","Lunch     6\n","Dinner    6\n","______________\n","                        mean\n","sex    smoker size          \n","Male   Yes    1     1.920000\n","              2     2.692927\n","              3     4.272857\n","              4     3.981111\n","              5     2.500000\n","              6          NaN\n","       No     1          NaN\n","              2     2.557544\n","              3     3.148824\n","              4     4.262632\n","              5     5.000000\n","              6     5.850000\n","Female Yes    1     1.000000\n","              2     2.736800\n","              3     3.846000\n","              4     4.045000\n","              5          NaN\n","              6          NaN\n","       No     1     1.415000\n","              2     2.370606\n","              3     2.918889\n","              4     4.014286\n","              5     5.140000\n","              6     4.600000\n","______________\n","         max                                                      ...   min  \\\n","sex     Male                             Female                   ...  Male   \n","size       1     2      3    4    5    6      1     2     3    4  ...     3   \n","smoker                                                            ...         \n","Yes     1.92  5.65  10.00  6.5  3.0  NaN   1.00  5.00  6.50  5.0  ...  2.00   \n","No       NaN  5.85   5.92  9.0  5.0  6.7   1.83  4.08  4.67  5.2  ...  1.66   \n","\n","                                                           \n","sex                   Female                               \n","size      4    5    6      1     2     3     4     5    6  \n","smoker                                                     \n","Yes     2.0  2.0  NaN    1.0  1.00  2.50  3.09   NaN  NaN  \n","No      2.0  5.0  5.0    1.0  1.01  1.36  2.45  5.14  4.2  \n","\n","[2 rows x 36 columns]\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-34-025b8479c940>:12: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n","  mean_day=print(tipsdata.groupby(['day', 'time'])['tip'].agg(['mean']))\n","<ipython-input-34-025b8479c940>:18: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n","  avg_size=print(tipsdata.groupby(['time'])['size'].agg(['mean']))\n","<ipython-input-34-025b8479c940>:20: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n","  avg_size=print(tipsdata.groupby(['time'])['size'].agg(['min']))\n","<ipython-input-34-025b8479c940>:22: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n","  avg_size=print(tipsdata.groupby(['time'])['size'].agg(['max']))\n","<ipython-input-34-025b8479c940>:27: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n","  print(tipsdata.groupby(['sex','smoker','size'])['tip'].agg(['mean'])),((['max'])),((['min']))\n","<ipython-input-34-025b8479c940>:29: FutureWarning: The default value of observed=False is deprecated and will change to observed=True in a future version of pandas. Specify observed=False to silence this warning and retain the current behavior\n","  pivoted_tips=tipsdata.pivot_table(index='smoker',columns=('sex', 'size'), values='tip',aggfunc=('mean', 'max', 'min'))\n"]},{"output_type":"execute_result","data":{"text/plain":["'\\n#pivot table is useful when we are using two or more categorical values like above.\\n\\n#what if I want to compute average of C value per value of A per value of B\\nprint(\"__________________\")\\nprint(\"with pivot_table\")\\npivoted_df = df.pivot_table(index=\\'A\\', columns=\\'B\\', values=\\'C\\',aggfunc=\\'mean\\')\\nprint(pivoted_df)\\n#you can use aggfunc parameter to set aggregation function to other things, like min, max and so on.\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":34}],"execution_count":null},{"metadata":{"id":"22cdbd87fd6c47c2"},"cell_type":"markdown","source":["\n","\n"],"id":"22cdbd87fd6c47c2"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"},"colab":{"provenance":[{"file_id":"15Bct6s-NkEkIxjRDn_jsexCN4RXo1aJ3","timestamp":1741887936689}]}},"nbformat":4,"nbformat_minor":5}